{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanning Shark CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing usefull libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import SRC.functions as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data project - Resources/attacks.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understand what type of data contains the .csv *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has (25723, 24) (rows/colums)\n",
      "Coulms: 24\n",
      "Rows: 25723\n"
     ]
    }
   ],
   "source": [
    "#How many row and collumns does it has\n",
    "print(f\"The df has {df.shape} (rows/colums)\")\n",
    "print(f\"Coulms: {fc.columns(df)}\")\n",
    "print(f\"Rows: {fc.rows(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The colums are the followin: ['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location', 'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time', 'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href', 'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']\n"
     ]
    }
   ],
   "source": [
    "# What kind of info can I find?\n",
    "print(f\"The colums are the followin: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Deleting usless info\n",
    "\n",
    "Analize the rows and columns in the dataframe that do not add value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 2.1 Delete duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete al duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has (6312, 24) (rows/colums)\n",
      "Coulms: 24\n",
      "Rows: 6312\n"
     ]
    }
   ],
   "source": [
    "# Analyze again\n",
    "print(f\"The df has {df.shape} (rows/colums)\")\n",
    "print(f\"Coulms: {fc.columns(df)}\")\n",
    "print(f\"Rows: {fc.rows(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 2.2 Delete columns with 95% of more missing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many colums has missing data? --> All of them ü§¶üèª‚Äç‚ôÄÔ∏è\n",
    "df.isnull().sum().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with missing info: 24\n",
      "Percentage of columns with missing info: 100.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 22               6311\n",
       "Unnamed: 23               6310\n",
       "Time                      3364\n",
       "Species                   2848\n",
       "Age                       2841\n",
       "Sex                        575\n",
       "Activity                   554\n",
       "Location                   550\n",
       "Fatal (Y/N)                549\n",
       "Area                       465\n",
       "Name                       220\n",
       "Country                     60\n",
       "Injury                      38\n",
       "Investigator or Source      27\n",
       "Type                        14\n",
       "Year                        12\n",
       "href formula                11\n",
       "pdf                         10\n",
       "href                        10\n",
       "Case Number.1               10\n",
       "Case Number.2               10\n",
       "Date                        10\n",
       "original order               3\n",
       "Case Number                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which column has the most missing data?\n",
    "print(f\"Number of columns with missing info: {df.isnull().sum().count()}\")\n",
    "print(f\"Percentage of columns with missing info: {fc.per_c_miss_info(df)} %\")\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 22', 'Unnamed: 23']\n"
     ]
    }
   ],
   "source": [
    "# Analize columns that has more than 95% info missing\n",
    "print(fc.col_miss_95(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those columns are not adding value so I'll delete them\n",
    "df = df.drop(fc.col_miss_95(df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time                      3364\n",
      "Species                   2848\n",
      "Age                       2841\n",
      "Sex                        575\n",
      "Activity                   554\n",
      "Location                   550\n",
      "Fatal (Y/N)                549\n",
      "Area                       465\n",
      "Name                       220\n",
      "Country                     60\n",
      "Injury                      38\n",
      "Investigator or Source      27\n",
      "Type                        14\n",
      "Year                        12\n",
      "href formula                11\n",
      "Case Number.2               10\n",
      "Date                        10\n",
      "pdf                         10\n",
      "href                        10\n",
      "Case Number.1               10\n",
      "original order               3\n",
      "Case Number                  2\n",
      "dtype: int64\n",
      "Columns: 22\n"
     ]
    }
   ],
   "source": [
    "# Validating that the columns with more than 95% null has been deleted\n",
    "print(df.isnull().sum().sort_values(ascending=False))\n",
    "print(f\"Columns: {fc.columns(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 2.3 Delete rows with 95% of more missing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6312"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows has missing data? --> All of them ü§¶üèª‚Äç‚ôÄÔ∏è\n",
    "df.T.isnull().sum().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 6312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6309, 8702, 25722]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analize rows that has more than 95% info missing\n",
    "print(f\"Rows: {fc.rows(df)}\")\n",
    "fc.row_miss_95(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those rows are not adding value so I'll delete them\n",
    "df = df.drop(fc.row_miss_95(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 6309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating that the rows with more than 95% null has been deleted\n",
    "print(f\"Rows: {fc.rows(df)}\")\n",
    "fc.row_miss_95(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning data to validate the hipothesis\n",
    "\n",
    "Deleting the not relevant info for the hipothesis validation:\n",
    " * The highest percentage of shark attacks to surfers happened in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review what info contains every column and slect what is usefull for the investigation and what is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                object\n",
       "Date                       object\n",
       "Year                      float64\n",
       "Type                       object\n",
       "Country                    object\n",
       "Area                       object\n",
       "Location                   object\n",
       "Activity                   object\n",
       "Name                       object\n",
       "Sex                        object\n",
       "Age                        object\n",
       "Injury                     object\n",
       "Fatal (Y/N)                object\n",
       "Time                       object\n",
       "Species                    object\n",
       "Investigator or Source     object\n",
       "pdf                        object\n",
       "href formula               object\n",
       "href                       object\n",
       "Case Number.1              object\n",
       "Case Number.2              object\n",
       "original order            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Daily Telegraph, 6/4/2018</td>\n",
       "      <td>2018.06.03.b-FlatRock.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.03.b</td>\n",
       "      <td>2018.06.03.b</td>\n",
       "      <td>6298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Diario de Pernambuco, 6/4/2018</td>\n",
       "      <td>2018.06.03.a-daSilva.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.03.a</td>\n",
       "      <td>2018.06.03.a</td>\n",
       "      <td>6297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K. McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.05.27-Ponce.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.05.27</td>\n",
       "      <td>2018.05.27</td>\n",
       "      <td>6296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.05.26.b-High.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.05.26.b</td>\n",
       "      <td>2018.05.26.b</td>\n",
       "      <td>6295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K. McMurray, Tracking Sharks.com</td>\n",
       "      <td>2018.05.26.a-DaytonaBeach.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.05.26.a</td>\n",
       "      <td>2018.05.26.a</td>\n",
       "      <td>6294.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Investigator or Source                            pdf  \\\n",
       "0                  R. Collier, GSAF           2018.06.25-Wolfe.pdf   \n",
       "1    K.McMurray, TrackingSharks.com         2018.06.18-McNeely.pdf   \n",
       "2    K.McMurray, TrackingSharks.com          2018.06.09-Denges.pdf   \n",
       "3                    B. Myatt, GSAF       2018.06.08-Arrawarra.pdf   \n",
       "4                         A .Kipper           2018.06.04-Ramos.pdf   \n",
       "5         Daily Telegraph, 6/4/2018      2018.06.03.b-FlatRock.pdf   \n",
       "6    Diario de Pernambuco, 6/4/2018       2018.06.03.a-daSilva.pdf   \n",
       "7   K. McMurray, TrackingSharks.com           2018.05.27-Ponce.pdf   \n",
       "8    K.McMurray, TrackingSharks.com          2018.05.26.b-High.pdf   \n",
       "9  K. McMurray, Tracking Sharks.com  2018.05.26.a-DaytonaBeach.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "5  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "7  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "8  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "9  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "5  http://sharkattackfile.net/spreadsheets/pdf_di...  2018.06.03.b   \n",
       "6  http://sharkattackfile.net/spreadsheets/pdf_di...  2018.06.03.a   \n",
       "7  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.05.27   \n",
       "8  http://sharkattackfile.net/spreadsheets/pdf_di...  2018.05.26.b   \n",
       "9  http://sharkattackfile.net/spreadsheets/pdf_di...  2018.05.26.a   \n",
       "\n",
       "  Case Number.2  original order  \n",
       "0    2018.06.25          6303.0  \n",
       "1    2018.06.18          6302.0  \n",
       "2    2018.06.09          6301.0  \n",
       "3    2018.06.08          6300.0  \n",
       "4    2018.06.04          6299.0  \n",
       "5  2018.06.03.b          6298.0  \n",
       "6  2018.06.03.a          6297.0  \n",
       "7    2018.05.27          6296.0  \n",
       "8  2018.05.26.b          6295.0  \n",
       "9  2018.05.26.a          6294.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date = df[['Investigator or Source', 'pdf', 'href formula', 'href', 'Case Number.1', 'Case Number.2', 'original order']]\n",
    "df_date.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting columns that are not adding value (because I don't know their meanning)\n",
    "df = df.drop(columns=['Investigator or Source', 'pdf', 'href formula', 'href', \n",
    "                 'Case Number.1', 'Case Number.2', 'original order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6303"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After claning the usless columns, I'll check if there is some duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "fc.rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number         Date  Year        Type             Country  \\\n",
       "6297     ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298     ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299     ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300     ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301     ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "\n",
       "                   Area                             Location      Activity  \\\n",
       "6297  Western Australia                          Roebuck Bay        Diving   \n",
       "6298  Western Australia                                  NaN  Pearl diving   \n",
       "6299     North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301   Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "\n",
       "                       Name Sex   Age  \\\n",
       "6297                   male    M  NaN   \n",
       "6298                  Ahmun    M  NaN   \n",
       "6299  Coast Guard personnel    M  NaN   \n",
       "6300        Jules Patterson    M  NaN   \n",
       "6301                   male    M   15   \n",
       "\n",
       "                                                 Injury Fatal (Y/N) Time  \\\n",
       "6297                                              FATAL           Y  NaN   \n",
       "6298                                              FATAL           Y  NaN   \n",
       "6299                                              FATAL           Y  NaN   \n",
       "6300                                              FATAL           Y  NaN   \n",
       "6301  FATAL. \"Shark bit him in half, carrying away t...           Y  NaN   \n",
       "\n",
       "     Species   \n",
       "6297      NaN  \n",
       "6298      NaN  \n",
       "6299      NaN  \n",
       "6300      NaN  \n",
       "6301      NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting usless rows\n",
    "df= df.drop(6302)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time           3354\n",
      "Species        2838\n",
      "Age            2831\n",
      "Sex             565\n",
      "Activity        544\n",
      "Location        540\n",
      "Fatal (Y/N)     539\n",
      "Area            455\n",
      "Name            210\n",
      "Country          50\n",
      "Injury           28\n",
      "Type              4\n",
      "Year              2\n",
      "Case Number       1\n",
      "Date              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time and Species and Sex will not de usefull for this investigation and has a los of null values\n",
    "df = df.drop(columns=['Time', 'Species ', 'Sex ', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has (6302, 11) (rows/colums)\n",
      "Rows: 6302\n",
      "Coulms: 11\n",
      "    Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
      "       'Activity', 'Name', 'Injury', 'Fatal (Y/N)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fc.print_shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigatinf the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Case Number'].value_counts().sort_index()\n",
    "# Case Number seem to be useless\n",
    "df = df.drop(columns=['Case Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'].value_counts().sort_index()\n",
    "# Year seem to be useless\n",
    "df = df.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boat             137\n",
       "Boating          203\n",
       "Boatomg            1\n",
       "Invalid          547\n",
       "Provoked         574\n",
       "Questionable       2\n",
       "Sea Disaster     239\n",
       "Unprovoked      4595\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florida                  1037\n",
       "New South Wales           486\n",
       "Queensland                311\n",
       "Hawaii                    298\n",
       "California                290\n",
       "                         ... \n",
       "Sumatra                     1\n",
       "30 nm from Singapore        1\n",
       "Oslo Fjord                  1\n",
       "Milne Bay  Province         1\n",
       "Ho Ha Wan Marine Park       1\n",
       "Name: Area, Length: 825, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Area'].value_counts().sort_values(ascending=False)\n",
    "# This si useful to split by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'].value_counts().sort_values()\n",
    "# Location seem to be useless because there is too much differenet locations\n",
    "df = df.drop(columns=['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing                                            971\n",
       "Swimming                                           869\n",
       "Fishing                                            431\n",
       "Spearfishing                                       333\n",
       "Bathing                                            162\n",
       "                                                  ... \n",
       "Net fishing                                          1\n",
       "Bitten after dhow shipwrecked                        1\n",
       "Dived into sea from launch & bitten immediately      1\n",
       "Adrift on refugee raft                               1\n",
       "Fishing from Surfboard                               1\n",
       "Name: Activity, Length: 1532, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Activity'].value_counts().sort_values(ascending=False)\n",
    "# This si useful to split by activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'].value_counts().sort_index()\n",
    "# Name seem to be useless\n",
    "df = df.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Injury'].value_counts().sort_index()\n",
    "# Injury seem to be useless\n",
    "df = df.drop(columns=['Injury'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fatal (Y/N)'].value_counts().sort_index()\n",
    "# 'Fatal (Y/N)' seem to be useless\n",
    "df = df.drop(columns=['Fatal (Y/N)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has (6302, 5) (rows/colums)\n",
      "Rows: 6302\n",
      "Coulms: 5\n",
      "    Index(['Date', 'Type', 'Country', 'Area', 'Activity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fc.print_shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicates again\n",
    "df_clean = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df has (6166, 5) (rows/colums)\n",
      "Rows: 6166\n",
      "Coulms: 5\n",
      "    Index(['Date', 'Type', 'Country', 'Area', 'Activity'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Paddling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Standing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Surfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Surfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>Free diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>Before 1903</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>Before 1903</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Pearl diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>1900-1905</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>1883-1889</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>1845-1853</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Swimming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6166 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Type             Country               Area  \\\n",
       "0     25-Jun-2018     Boating                 USA         California   \n",
       "1     18-Jun-2018  Unprovoked                 USA            Georgia   \n",
       "2     09-Jun-2018     Invalid                 USA             Hawaii   \n",
       "3     08-Jun-2018  Unprovoked           AUSTRALIA    New South Wales   \n",
       "4     04-Jun-2018    Provoked              MEXICO             Colima   \n",
       "...           ...         ...                 ...                ...   \n",
       "6297  Before 1903  Unprovoked           AUSTRALIA  Western Australia   \n",
       "6298  Before 1903  Unprovoked           AUSTRALIA  Western Australia   \n",
       "6299    1900-1905  Unprovoked                 USA     North Carolina   \n",
       "6300    1883-1889  Unprovoked              PANAMA                NaN   \n",
       "6301    1845-1853  Unprovoked  CEYLON (SRI LANKA)   Eastern Province   \n",
       "\n",
       "          Activity  \n",
       "0         Paddling  \n",
       "1         Standing  \n",
       "2          Surfing  \n",
       "3          Surfing  \n",
       "4      Free diving  \n",
       "...            ...  \n",
       "6297        Diving  \n",
       "6298  Pearl diving  \n",
       "6299      Swimming  \n",
       "6300           NaN  \n",
       "6301      Swimming  \n",
       "\n",
       "[6166 rows x 5 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.print_shape(df_clean)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exporting clean file to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"../../Data project - Resources/attacks_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
